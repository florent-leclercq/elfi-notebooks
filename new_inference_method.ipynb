{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Basic-structure\" data-toc-modified-id=\"Basic-structure-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Basic structure</a></span></li><li><span><a href=\"#Adding-an-updated-method\" data-toc-modified-id=\"Adding-an-updated-method-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Adding an updated method</a></span></li><li><span><a href=\"#Set-threshold-and-number-of-simulations\" data-toc-modified-id=\"Set-threshold-and-number-of-simulations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Set threshold and number of simulations</a></span></li><li><span><a href=\"#Extract-the-results\" data-toc-modified-id=\"Extract-the-results-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Extract the results</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from elfi.methods.parameter_inference import ParameterInference\n",
    "\n",
    "class CustomMethod(ParameterInference):\n",
    "\n",
    "    def __init__(self, model, output_names, **kwargs):\n",
    "        super(CustomMethod, self).__init__(model, output_names, **kwargs)\n",
    "\n",
    "    def set_objective(self):\n",
    "        # Request 3 batches to be generated\n",
    "        self.objective['n_batches'] = 3\n",
    "\n",
    "    def extract_result(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_batches': 3, 'n_sim': 3000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import elfi.examples.ma2 as ma2\n",
    "\n",
    "# Get a ready made MA2 model to test our inference method with\n",
    "m = ma2.get_model()\n",
    "\n",
    "# We want the outputs from node 'd' of the model `m` to be available\n",
    "custom_method = CustomMethod(m, ['d'])\n",
    "\n",
    "# Run the inference\n",
    "custom_method.infer()  # {'n_batches': 3, 'n_sim': 3000}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding an updated method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomMethod(ParameterInference):\n",
    "    def __init__(self, model, output_names, **kwargs):\n",
    "        super(CustomMethod, self).__init__(model, output_names, **kwargs)\n",
    "\n",
    "        # Hard code a threshold and discrepancy node name for now\n",
    "        self.threshold = .1\n",
    "        self.discrepancy_name = output_names[0]\n",
    "\n",
    "        # Prepare lists to push the filtered outputs into\n",
    "        self.state['filtered_outputs'] = {name: [] for name in output_names}\n",
    "\n",
    "    def update(self, batch, batch_index):\n",
    "        super(CustomMethod, self).update(batch, batch_index)\n",
    "\n",
    "        # Make a filter mask (logical numpy array) from the distance array\n",
    "        filter_mask = batch[self.discrepancy_name] <= self.threshold\n",
    "\n",
    "        # Append the filtered parameters to their lists\n",
    "        for name in self.output_names:\n",
    "            values = batch[name]\n",
    "            self.state['filtered_outputs'][name].append(values[filter_mask])\n",
    "\n",
    "    # other methods as before\n",
    "    def set_objective(self):\n",
    "        # Request 3 batches to be generated\n",
    "        self.objective['n_batches'] = 3\n",
    "\n",
    "    def extract_result(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filtered_outputs': {'d': [array([ 0.04118507,  0.00667366,  0.09887394,  0.09115247,  0.01787308,\n",
       "           0.09096578,  0.03155234]),\n",
       "   array([ 0.09199846]),\n",
       "   array([ 0.01787483,  0.05463452,  0.06729574,  0.043176  ,  0.01443466,\n",
       "           0.09046322])]},\n",
       " 'n_batches': 3,\n",
       " 'n_sim': 3000}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a ready made MA2 model to test our inference method with\n",
    "m = ma2.get_model()\n",
    "\n",
    "# We want the outputs from node 'd' of the model `m` to be available\n",
    "custom_method = CustomMethod(m, ['d'])\n",
    "\n",
    "# Run the inference\n",
    "custom_method.infer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set threshold and number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomMethod(ParameterInference):\n",
    "    def __init__(self, model, discrepancy_name, threshold, **kwargs):\n",
    "        # Create a name list of nodes whose outputs we wish to receive\n",
    "        output_names = [discrepancy_name] + model.parameter_names\n",
    "        super(CustomMethod, self).__init__(model, output_names, **kwargs)\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.discrepancy_name = discrepancy_name\n",
    "\n",
    "        # Prepare lists to push the filtered outputs into\n",
    "        self.state['filtered_outputs'] = {name: [] for name in output_names}\n",
    "\n",
    "\n",
    "    def update(self, batch, batch_index):\n",
    "        super(CustomMethod, self).update(batch, batch_index)\n",
    "\n",
    "        # Make a filter mask (logical numpy array) from the distance array\n",
    "        filter_mask = batch[self.discrepancy_name] <= self.threshold\n",
    "\n",
    "        # Append the filtered parameters to their lists\n",
    "        for name in self.output_names:\n",
    "            values = batch[name]\n",
    "            self.state['filtered_outputs'][name].append(values[filter_mask])\n",
    "\n",
    "    def set_objective(self, n_sim):\n",
    "        self.objective['n_sim'] = n_sim\n",
    "\n",
    "    def extract_result(self):\n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filtered_outputs': {'d': [array([ 0.07274003,  0.05496166,  0.03369005,  0.02783118,  0.06705382]),\n",
       "   array([ 0.04938172,  0.039332  ,  0.04218729])],\n",
       "  't1': [array([ 0.67284382,  0.76477027,  0.62571009,  0.46825312,  0.54522481]),\n",
       "   array([ 0.60167879,  1.08463265,  0.8094352 ])],\n",
       "  't2': [array([ 0.54927791,  0.45852012,  0.27436906,  0.75507334,  0.89443866]),\n",
       "   array([ 0.65363971,  0.92425147,  0.35309849])]},\n",
       " 'n_batches': 2,\n",
       " 'n_sim': 2000}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the inference\n",
    "custom_method = CustomMethod(m, 'd', threshold=.1, batch_size=1000)\n",
    "custom_method.infer(n_sim=2000)  # {'n_batches': 2, 'n_sim': 2000, 'filtered_outputs': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filtered_outputs': {'d': [array([ 0.07274003,  0.05496166,  0.03369005,  0.02783118,  0.06705382]),\n",
       "   array([ 0.04938172,  0.039332  ,  0.04218729]),\n",
       "   array([ 0.05017163,  0.0777252 ,  0.08430152,  0.0835376 ]),\n",
       "   array([ 0.01315948,  0.05887771,  0.02284609,  0.07160721,  0.05499586])],\n",
       "  't1': [array([ 0.67284382,  0.76477027,  0.62571009,  0.46825312,  0.54522481]),\n",
       "   array([ 0.60167879,  1.08463265,  0.8094352 ]),\n",
       "   array([ 0.72408381,  0.36986854,  0.65311972,  0.56907475]),\n",
       "   array([ 0.56842926,  0.67583018,  0.94228685,  0.62502374,  0.51659568])],\n",
       "  't2': [array([ 0.54927791,  0.45852012,  0.27436906,  0.75507334,  0.89443866]),\n",
       "   array([ 0.65363971,  0.92425147,  0.35309849]),\n",
       "   array([ 0.49265925,  0.76532727,  0.42632809,  0.73731674]),\n",
       "   array([ 0.16269547,  0.48695546,  0.44987195,  0.51514191,  0.20618901])]},\n",
       " 'n_batches': 4,\n",
       " 'n_sim': 4000}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continue inference from the previous state (with n_sim=2000)\n",
    "custom_method.infer(n_sim=4000) # {'n_batches': 4, 'n_sim': 4000, 'filtered_outputs': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filtered_outputs': {'d': [array([ 0.07274003,  0.05496166,  0.03369005,  0.02783118,  0.06705382]),\n",
       "   array([ 0.04938172,  0.039332  ,  0.04218729]),\n",
       "   array([ 0.05017163,  0.0777252 ,  0.08430152,  0.0835376 ]),\n",
       "   array([ 0.01315948,  0.05887771,  0.02284609,  0.07160721,  0.05499586]),\n",
       "   array([ 0.03626514,  0.01565701,  0.09034186,  0.08375578,  0.09544032,\n",
       "           0.06725741])],\n",
       "  't1': [array([ 0.67284382,  0.76477027,  0.62571009,  0.46825312,  0.54522481]),\n",
       "   array([ 0.60167879,  1.08463265,  0.8094352 ]),\n",
       "   array([ 0.72408381,  0.36986854,  0.65311972,  0.56907475]),\n",
       "   array([ 0.56842926,  0.67583018,  0.94228685,  0.62502374,  0.51659568]),\n",
       "   array([ 0.64612478,  0.76469718,  0.38542154,  0.55239334,  0.38164821,\n",
       "           0.53674665])],\n",
       "  't2': [array([ 0.54927791,  0.45852012,  0.27436906,  0.75507334,  0.89443866]),\n",
       "   array([ 0.65363971,  0.92425147,  0.35309849]),\n",
       "   array([ 0.49265925,  0.76532727,  0.42632809,  0.73731674]),\n",
       "   array([ 0.16269547,  0.48695546,  0.44987195,  0.51514191,  0.20618901]),\n",
       "   array([ 0.54237938,  0.8708257 ,  0.51615224,  0.85805695,  0.92578473,\n",
       "           0.83929393])]},\n",
       " 'n_batches': 5,\n",
       " 'n_sim': 5000}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or use it iteratively\n",
    "custom_method.set_objective(n_sim=6000)\n",
    "\n",
    "custom_method.iterate()\n",
    "assert custom_method.finished == False\n",
    "# Investigate the current state\n",
    "custom_method.extract_result()  # {'n_batches': 5, 'n_sim': 5000, 'filtered_outputs': ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filtered_outputs': {'d': [array([ 0.07274003,  0.05496166,  0.03369005,  0.02783118,  0.06705382]),\n",
       "   array([ 0.04938172,  0.039332  ,  0.04218729]),\n",
       "   array([ 0.05017163,  0.0777252 ,  0.08430152,  0.0835376 ]),\n",
       "   array([ 0.01315948,  0.05887771,  0.02284609,  0.07160721,  0.05499586]),\n",
       "   array([ 0.03626514,  0.01565701,  0.09034186,  0.08375578,  0.09544032,\n",
       "           0.06725741]),\n",
       "   array([ 0.0316558 ,  0.09233554,  0.04304713])],\n",
       "  't1': [array([ 0.67284382,  0.76477027,  0.62571009,  0.46825312,  0.54522481]),\n",
       "   array([ 0.60167879,  1.08463265,  0.8094352 ]),\n",
       "   array([ 0.72408381,  0.36986854,  0.65311972,  0.56907475]),\n",
       "   array([ 0.56842926,  0.67583018,  0.94228685,  0.62502374,  0.51659568]),\n",
       "   array([ 0.64612478,  0.76469718,  0.38542154,  0.55239334,  0.38164821,\n",
       "           0.53674665]),\n",
       "   array([ 0.75710197,  0.72997056,  0.28815311])],\n",
       "  't2': [array([ 0.54927791,  0.45852012,  0.27436906,  0.75507334,  0.89443866]),\n",
       "   array([ 0.65363971,  0.92425147,  0.35309849]),\n",
       "   array([ 0.49265925,  0.76532727,  0.42632809,  0.73731674]),\n",
       "   array([ 0.16269547,  0.48695546,  0.44987195,  0.51514191,  0.20618901]),\n",
       "   array([ 0.54237938,  0.8708257 ,  0.51615224,  0.85805695,  0.92578473,\n",
       "           0.83929393]),\n",
       "   array([ 0.90804793,  0.19117608,  0.4411636 ])]},\n",
       " 'n_batches': 6,\n",
       " 'n_sim': 6000}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_method.iterate()\n",
    "assert custom_method.finished\n",
    "custom_method.extract_result()  # {'n_batches': 6, 'n_sim': 6000, 'filtered_outputs': ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from elfi.methods.parameter_inference import ParameterInference\n",
    "from elfi.methods.results import Sample\n",
    "\n",
    "class CustomMethod(ParameterInference):\n",
    "    def __init__(self, model, discrepancy_name, threshold, **kwargs):\n",
    "        # Create a name list of nodes whose outputs we wish to receive\n",
    "        output_names = [discrepancy_name] + model.parameter_names\n",
    "        super(CustomMethod, self).__init__(model, output_names, **kwargs)\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.discrepancy_name = discrepancy_name\n",
    "\n",
    "        # Prepare lists to push the filtered outputs into\n",
    "        self.state['filtered_outputs'] = {name: [] for name in output_names}\n",
    "\n",
    "    def set_objective(self, n_sim):\n",
    "        self.objective['n_sim'] = n_sim\n",
    "\n",
    "    def update(self, batch, batch_index):\n",
    "        super(CustomMethod, self).update(batch, batch_index)\n",
    "\n",
    "        # Make a filter mask (logical numpy array) from the distance array\n",
    "        filter_mask = batch[self.discrepancy_name] <= self.threshold\n",
    "\n",
    "        # Append the filtered parameters to their lists\n",
    "        for name in self.output_names:\n",
    "            values = batch[name]\n",
    "            self.state['filtered_outputs'][name].append(values[filter_mask])\n",
    "\n",
    "    def extract_result(self):\n",
    "        filtered_outputs = self.state['filtered_outputs']\n",
    "        outputs = {name: np.concatenate(filtered_outputs[name]) for name in self.output_names}\n",
    "\n",
    "        return Sample(\n",
    "            method_name='CustomMethod',\n",
    "            outputs=outputs,\n",
    "            parameter_names=self.parameter_names,\n",
    "            discrepancy_name=self.discrepancy_name,\n",
    "            n_sim=self.state['n_sim'],\n",
    "            threshold=self.threshold\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Method: CustomMethod\n",
       "Number of samples: 7\n",
       "Number of simulations: 2000\n",
       "Threshold: 0.1\n",
       "Sample means: t1: 0.551, t2: 0.564"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the inference\n",
    "custom_method = CustomMethod(m, 'd', threshold=.1, batch_size=1000)\n",
    "custom_method.infer(n_sim=2000) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
